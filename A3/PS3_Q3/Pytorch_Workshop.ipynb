{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c299ea74",
   "metadata": {},
   "source": [
    "\n",
    "# Workshop: Introduction to PyTorch and Deep Learning on DNA Sequences\n",
    "\n",
    " In this tutorial, you'll learn how to use PyTorch to build, train, and evaluate neural networks for taxonomic classification of DNA sequences.\n",
    "\n",
    "\n",
    "Let's get started! Make sure you have PyTorch installed to run the code cells in this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09af4b3",
   "metadata": {},
   "source": [
    "\n",
    "## 1: Introduction to PyTorch\n",
    "\n",
    "In this part, we'll learn the fundamentals of PyTorch, starting with tensors, the building blocks for any deep learning framework.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596d5bc7",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1 Tensors and PyTorch Basics\n",
    "\n",
    "Tensors are multi-dimensional arrays and are the primary data structure in PyTorch. You can think of them as similar to NumPy arrays, but they are optimized for GPU operations.\n",
    "\n",
    "Let's create some basic tensors and perform operations on them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b2bda1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "Random Tensor:\n",
      " tensor([[0.3419, 0.3777, 0.2065],\n",
      "        [0.0987, 0.0702, 0.2707],\n",
      "        [0.4607, 0.2155, 0.4208]])\n",
      "\n",
      "Sum of Tensors:\n",
      " tensor([[2, 4],\n",
      "        [6, 8]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# Create a tensor\n",
    "tensor_a = torch.tensor([[1, 2], [3, 4]])\n",
    "print(\"Tensor A:\\n\", tensor_a)\n",
    "\n",
    "# Creating a random tensor\n",
    "random_tensor = torch.rand((3, 3))\n",
    "print(\"\\nRandom Tensor:\\n\", random_tensor)\n",
    "\n",
    "# Basic tensor operations\n",
    "sum_tensor = tensor_a + tensor_a\n",
    "print(\"\\nSum of Tensors:\\n\", sum_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6f6909",
   "metadata": {},
   "source": [
    ">### Exercise: Create your own tensors and try different operations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b6a837",
   "metadata": {},
   "source": [
    "\n",
    "### Additional Tensor Operations: Reshaping, Slicing, and Element-wise Operations\n",
    "\n",
    "In this section, we'll explore a few more tensor operations that are commonly used in deep learning workflows.\n",
    "\n",
    "#### Reshaping\n",
    "PyTorch provides ways to change the shape of a tensor without altering its data, such as using `.view()` or `.reshape()`.\n",
    "\n",
    "#### Slicing and Indexing\n",
    "You can select parts of tensors using slicing, similar to how you would slice arrays in NumPy.\n",
    "\n",
    "#### Element-wise Operations\n",
    "PyTorch supports element-wise operations, such as addition, subtraction, multiplication, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac6014e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "Reshaped Tensor (4x4):\n",
      " tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "\n",
      "Selecting the first row: tensor([0, 1, 2, 3])\n",
      "Selecting the first column: tensor([ 0,  4,  8, 12])\n",
      "Selecting a sub-tensor:\n",
      " tensor([[ 5,  6],\n",
      "        [ 9, 10]])\n",
      "\n",
      "Tensor B:\n",
      " tensor([[2, 2, 2, 2],\n",
      "        [3, 3, 3, 3],\n",
      "        [4, 4, 4, 4],\n",
      "        [5, 5, 5, 5]])\n",
      "\n",
      "Element-wise Addition:\n",
      " tensor([[ 2,  3,  4,  5],\n",
      "        [ 7,  8,  9, 10],\n",
      "        [12, 13, 14, 15],\n",
      "        [17, 18, 19, 20]])\n",
      "Element-wise Multiplication:\n",
      " tensor([[ 0,  2,  4,  6],\n",
      "        [12, 15, 18, 21],\n",
      "        [32, 36, 40, 44],\n",
      "        [60, 65, 70, 75]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reshaping Tensors\n",
    "tensor_a = torch.arange(16)  # Create a 1D tensor with values 0 to 15\n",
    "print(\"Original Tensor:\", tensor_a)\n",
    "\n",
    "reshaped_tensor = tensor_a.view(4, 4)  # Reshape to 4x4\n",
    "print(\"Reshaped Tensor (4x4):\\n\", reshaped_tensor)\n",
    "\n",
    "# Slicing and Indexing\n",
    "print(\"\\nSelecting the first row:\", reshaped_tensor[0])         # Select first row\n",
    "print(\"Selecting the first column:\", reshaped_tensor[:, 0])      # Select first column\n",
    "print(\"Selecting a sub-tensor:\\n\", reshaped_tensor[1:3, 1:3])  # Select a 2x2 sub-tensor\n",
    "\n",
    "# Element-wise Operations\n",
    "tensor_b = torch.tensor([[2, 2, 2, 2], [3, 3, 3, 3], [4, 4, 4, 4], [5, 5, 5, 5]])\n",
    "print(\"\\nTensor B:\\n\", tensor_b)\n",
    "\n",
    "added_tensor = reshaped_tensor + tensor_b\n",
    "print(\"\\nElement-wise Addition:\\n\", added_tensor)\n",
    "\n",
    "multiplied_tensor = reshaped_tensor * tensor_b\n",
    "print(\"Element-wise Multiplication:\\n\", multiplied_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94fe274",
   "metadata": {},
   "source": [
    "> ### Exercise: Try reshaping, slicing, and performing element-wise operations with different dimensions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f137a298",
   "metadata": {},
   "source": [
    "\n",
    "### 1.2 The `nn` Module and Building a Simple Neural Network\n",
    "\n",
    "PyTorch provides the `torch.nn` module to help define neural networks. Let's define a simple fully connected neural network and explore its components.\n",
    "\n",
    "Below is a simple feed-forward neural network with a couple of layers. We'll define this model and briefly discuss the components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd25afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=20, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleNN(input_size=10, hidden_size=20, num_classes=3)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe39c088",
   "metadata": {},
   "source": [
    "\n",
    "### 1.3 Creating a Toy Dataset\n",
    "\n",
    "Let's create a small random dataset for classification. This will help us understand how the training loop and loss function work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55e78829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch: [tensor([[-3.8080e-01, -2.1356e-03,  8.1096e-01, -1.8996e+00,  8.4224e-02,\n",
      "         -2.5316e+00,  9.5041e-01,  1.2297e+00, -2.1863e+00,  6.1889e-01],\n",
      "        [ 1.4225e+00, -6.4338e-01, -3.1275e+00,  2.1705e+00, -1.0950e+00,\n",
      "          5.8291e-01, -1.7202e+00, -7.3819e-01, -1.6831e+00, -1.4407e+00],\n",
      "        [-1.4680e+00, -7.4585e-01,  1.6721e+00, -2.2160e+00,  2.1608e+00,\n",
      "         -5.9191e-01,  3.2951e-01, -1.3191e+00,  1.6106e+00, -3.8513e-01],\n",
      "        [-8.9634e-02,  6.7160e-01,  4.3028e-02,  1.8721e+00, -6.0660e-02,\n",
      "          3.0383e+00, -8.3419e-01, -2.5616e+00,  2.3328e+00,  1.6661e-03],\n",
      "        [-2.4882e+00,  5.8942e-01,  1.7997e+00,  3.1415e-01,  3.9802e+00,\n",
      "          8.5156e-02,  7.1867e-01,  1.4972e+00,  4.0995e+00, -1.3317e+00],\n",
      "        [ 7.9621e-01,  4.9196e-01,  8.5864e-02, -7.2046e-01, -6.0964e-01,\n",
      "         -2.0936e+00, -1.1053e-01,  1.7644e+00, -1.2465e-01,  4.8280e-01],\n",
      "        [-1.3949e+00, -2.5379e-01, -1.6233e-01, -2.7198e+00,  3.6985e+00,\n",
      "          6.0304e-01,  1.1970e-01,  1.3385e+00,  3.0670e+00, -3.0139e+00],\n",
      "        [ 2.3123e+00,  5.4674e-01, -1.5524e+00,  8.2866e-01, -1.5995e+00,\n",
      "          1.2772e+00,  5.3440e-01, -9.3159e-01,  2.9072e+00, -3.4286e-01],\n",
      "        [ 1.8773e+00,  9.8708e-02, -2.6497e+00,  6.2748e-01, -1.2749e+00,\n",
      "          1.1809e+00, -5.0554e-01,  8.7131e-01,  9.7046e-02, -1.2649e+00],\n",
      "        [-3.9608e-01,  6.0194e-02, -1.2384e+00,  7.3914e-01,  4.1710e-01,\n",
      "          2.2752e+00,  3.5764e-01, -8.3237e-01, -7.6584e-01, -1.2213e+00]]), tensor([0, 0, 2, 1, 2, 0, 2, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import make_classification\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Generate a toy dataset with 3 classes\n",
    "X, y = make_classification(n_samples=100, n_features=10, n_classes=3, n_informative=5)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Print a sample batch\n",
    "for batch in dataloader:\n",
    "    print(\"Sample batch:\", batch)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa87caa",
   "metadata": {},
   "source": [
    "\n",
    "### 1.4 Setting Up a Training Loop with Cross-Entropy Loss\n",
    "\n",
    "The training loop involves feeding data into the model, computing the loss, performing backpropagation, and updating model parameters.\n",
    "\n",
    "#### Understanding Cross-Entropy Loss\n",
    "Cross-entropy loss is commonly used for classification tasks. It calculates the difference between the predicted probability distribution and the true distribution.\n",
    "\n",
    "Let's set up the training loop using cross-entropy loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e82c2e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.1347\n",
      "Epoch [2/5], Loss: 1.1040\n",
      "Epoch [3/5], Loss: 1.0667\n",
      "Epoch [4/5], Loss: 1.0530\n",
      "Epoch [5/5], Loss: 1.0809\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up the loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_iDeLUCS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
